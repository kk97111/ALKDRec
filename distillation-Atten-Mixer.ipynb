{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee02346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation = 'ALKERec'#['ALKERec','RAD-BC','random','easiest','hardest','TR']\n",
    "name = 'Games' #['Games','ML']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5f2cde-6a2e-48ff-8cba-1bfb60e24841",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from utils.dataset import Dataset,DataIterator,get_DataLoader\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "def parse_args(name):   \n",
    "    parser = argparse.ArgumentParser(description=\"Run .\")  \n",
    "    parser.add_argument('--model', nargs='?', default='STAMP_S_distill')\n",
    "    parser.add_argument('--dataset', nargs='?', default=name,\n",
    "                        help='Choose a dataset.')\n",
    "    parser.add_argument('--batch_size', type=int, default=1024,\n",
    "                        help='Batch size.')\n",
    "    parser.add_argument('--hidden_factor', type=int, default=10,\n",
    "                        help='Number of hidden factors.')\n",
    "    parser.add_argument('--lamda', type=float, default = 10e-5,\n",
    "                        help='Regularizer for bilinear part.')\n",
    "    parser.add_argument('--lr', type=float, default=0.0001,\n",
    "                        help='Learning rate.')\n",
    "    parser.add_argument('--per_test', type=int, default=20,\n",
    "                        help='Learning rate.')   \n",
    "    parser.add_argument('--topN', type=int, default=50,\n",
    "                        help='Learning rate.')  \n",
    "    return parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23339538-91a8-4984-8299-ea4e6d2f7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def demonstrate_randomness(seed=2024):\n",
    "    # 设置 Python 内置的随机种子\n",
    "    random.seed(seed)    \n",
    "    # 设置 Numpy 的随机种子\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 设置 PyTorch 的随机种子\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # 确保 PyTorch 的一致性行为\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 调用函数\n",
    "demonstrate_randomness()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55f6f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data: meta_data\n",
      "\n",
      "loading data: interaction_data\n",
      "\n",
      "split data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = parse_args(name)\n",
    "data = Dataset(args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ae8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.log import LOG, load_model, save_model\n",
    "log = LOG(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02253da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using time span 128\n",
      "total session: 12054\n",
      "Using time span 128\n",
      "total session: 4018\n",
      "Using time span 128\n",
      "total session: 4019\n"
     ]
    }
   ],
   "source": [
    "train_data =  get_DataLoader(data.train,args.batch_size, seq_len=10)\n",
    "valid_data =  get_DataLoader(data.valid,args.batch_size, seq_len=10,train_flag=0)\n",
    "test_data =  get_DataLoader(data.test,args.batch_size, seq_len=10,train_flag=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90cef37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AttMix import AttMix\n",
    "model = AttMix(data.n_item,args.hidden_factor,args.batch_size,args)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4aa2bd-6b56-435d-bcd0-bddf3d6be578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from ./best_model/Games+AttMix_S\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import calculate_session_embs\n",
    "BASE = AttMix\n",
    "best_model_path_student = './best_model/'+'%s+AttMix_S'%args.dataset\n",
    "#load Student model\n",
    "model = BASE(data.n_item,args.hidden_factor,args.batch_size,args)    \n",
    "load_model(model, best_model_path_student)\n",
    "model = model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d52ac22-105a-43e4-9e55-2d4e1eaa588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database_LLM(object):\n",
    "    def __init__(self,path):\n",
    "        #|session_id|rec_result|hint_position|\n",
    "        self.dir = path\n",
    "        self.exist_sessions()\n",
    "    def exist_sessions(self):\n",
    "        # 计算文件的行数\n",
    "        self.exist_session = list()\n",
    "        with open(self.dir, 'r', encoding='utf-8') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                session_id, rec_result, hint_position = line.split('\\t')\n",
    "                self.exist_session.append(int(session_id))\n",
    "    def write(self,session_id,rec_result,hint_position):\n",
    "        with open(self.dir,'a') as f:\n",
    "            f.write(\"%d\\t%s\\t%d\\n\"%(session_id,str(rec_result),hint_position))\n",
    "        self.exist_sessions()\n",
    "    def get_all_dict(self):\n",
    "        table_rec = dict()\n",
    "        table_hit = dict()\n",
    "        with open(self.dir, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                session_id,rec_result,hint_position =line.split('\\t')\n",
    "                table_rec[int(session_id)] = eval(rec_result)\n",
    "                table_hit[int(session_id)] = eval(hint_position[:-1])\n",
    "        return table_rec,table_hit\n",
    "    def write_sub_database(self,sub_dir,session_id):\n",
    "        with open(sub_dir,'a') as f:\n",
    "            f.write(\"%d\\n\"%session_id)\n",
    "    def read_sub_database(self,sub_dir,st=0,end=50000):\n",
    "        r = set()\n",
    "        with open(sub_dir) as f:\n",
    "            for i,line in enumerate(f):\n",
    "                if i >= st and i <= end:\n",
    "                    r.add(int(line[:-1]))\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a2a7c03-58ef-4d2e-a8f0-0ae058a6b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './datasets/%s/%s_LLM_Database.data'%(args.dataset,args.dataset)\n",
    "database = Database_LLM(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30b4eb10-9c57-4b2b-b9a1-d525571bd8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('./datasets/%s/%s_prediction.pkl'%(args.dataset,args.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81033ca3-7096-4b3b-86b7-d58d417639dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4058025/4249407072.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_df['LLM_pred'] = [table_rec[session_id] for session_id in sub_df.session_id]\n",
      "/tmp/ipykernel_4058025/4249407072.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_df['LLM_hit'] = [table_hit[session_id] for session_id in sub_df.session_id]\n"
     ]
    }
   ],
   "source": [
    "sub_df = df[df['session_id'].isin(database.exist_session)]\n",
    "table_rec,table_hit = database.get_all_dict()\n",
    "sub_df['LLM_pred'] = [table_rec[session_id] for session_id in sub_df.session_id]\n",
    "sub_df['LLM_hit'] = [table_hit[session_id] for session_id in sub_df.session_id]\n",
    "print(len(sub_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4ec39b9-a774-4af4-9c0a-44fd841003af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ablation == 'TR':\n",
    "    select_df = df\n",
    "else:\n",
    "    ablation_sessions = database.read_sub_database('./datasets/%s/%s_%s.base'%(args.dataset,args.dataset,ablation),0,499)\n",
    "    select_df =  sub_df[sub_df['session_id'].isin(ablation_sessions)]\n",
    "    select_df = select_df\n",
    "    other_df = df[~df['session_id'].isin(ablation_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef431c3b-129a-4cad-bff8-fa551344ab22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(select_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6c0e5b-e24e-4ca6-89ef-f12fa327b069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.506\n",
      "0.506\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if ablation != 'TR':\n",
    "    #k1 + k2\n",
    "    print(len(select_df[select_df.LLM_hit<25])/len(select_df))\n",
    "    #k2\n",
    "    print(len(select_df[(select_df.difference <= np.median(select_df.difference.values)) & (select_df.LLM_hit<25)])/len(select_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc73fca-dea1-45d8-8ae8-29b81b79ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug = []\n",
    "negative_sampler = {key:[] for key in set(select_df.session_id.values)}\n",
    "for i in range(len(select_df)):\n",
    "    line = select_df.iloc[i]\n",
    "    session = line.feature\n",
    "    session_id = line.session_id\n",
    "    if ablation == 'TR':\n",
    "        LLM_pred = line.teacher_top_item\n",
    "        for j,item in enumerate(LLM_pred):\n",
    "            train_aug.append([session,item,session_id])\n",
    "\n",
    "    else:\n",
    "        LLM_pred = line.LLM_pred\n",
    "        for j,item in enumerate(LLM_pred):\n",
    "            if j<= 5:\n",
    "                train_aug.append([session,item,session_id])\n",
    "            if j<= 15:\n",
    "                train_aug.append([session,item,session_id])\n",
    "            if j<= 25:\n",
    "                train_aug.append([session,item,session_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22314286-d639-4f42-86a5-ff819bea27a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22748\n"
     ]
    }
   ],
   "source": [
    "train_aug = pd.DataFrame(train_aug,columns=data.train.columns)\n",
    "print(len(train_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06dd5a03-7bcb-48f9-88ab-6741c84d9a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using time span 128\n",
      "total session: 22748\n"
     ]
    }
   ],
   "source": [
    "train_aug_data =  get_DataLoader(train_aug, 1024, seq_len=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb455172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "iter: 0, train loss: 0.7509, valid recall: 0.017422, valid ndcg: 0.006384\n",
      "time interval: 0.0098 min\n",
      "20\n",
      "iter: 20, train loss: 0.7467, valid recall: 0.017422, valid ndcg: 0.006372\n",
      "time interval: 0.0059 min\n",
      "40\n",
      "iter: 40, train loss: 0.7326, valid recall: 0.016924, valid ndcg: 0.006222\n",
      "time interval: 0.0060 min\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from utils.evaluation import evaluate\n",
    "from utils.log import load_model, save_model\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "def to_tensor(var, device):\n",
    "    var = torch.Tensor(var)\n",
    "    var = var.to(device)\n",
    "    return var.long()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)#, weight_decay=args.weight_decay)\n",
    "best_metric = 0\n",
    "for iter, (targets, items, mask,session_id) in enumerate(train_aug_data):\n",
    "    #训练\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    targets_cuda = to_tensor(targets,'cuda')\n",
    "    items_cuda = to_tensor(items,'cuda')\n",
    "    mask_cuda = to_tensor(mask,'cuda')\n",
    "    # negative_cuda = to_tensor(data.hard_negative_sample(session_id,negative_sampler,10),'cuda')\n",
    "    negative_cuda = to_tensor(data.uniform_negative_sample(targets_cuda,1),'cuda')\n",
    "    user_eb, scores = model(items_cuda,mask_cuda)\n",
    "    loss = model.loss(user_eb,targets_cuda,negative_cuda)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iter % args.per_test  == 0:#\n",
    "        start_time = time.time()\n",
    "        print(iter)\n",
    "        model.eval()\n",
    "        metrics = evaluate(model, valid_data,15,args=args)\n",
    "        log_str = 'iter: %d, train loss: %.4f' % (iter, loss) # 打印loss\n",
    "        if metrics != {}:\n",
    "            log_str += ', ' + ', '.join(['valid ' + key + ': %.6f' % value for key, value in metrics.items()])\n",
    "        print(log_str)\n",
    "        log.write_str(log_str)\n",
    "        # 保存recall最佳的模型\n",
    "        if 'recall' in metrics:\n",
    "            recall = metrics['recall']\n",
    "            if recall > best_metric:\n",
    "                best_metric = recall\n",
    "                save_model(model, log.best_model_path)\n",
    "                trials = 0\n",
    "            else:\n",
    "                trials += 1\n",
    "                args.patience = 20 #if args.dataset =='rocket' else 3 \n",
    "                if trials > args.patience: # early stopping\n",
    "                    print(\"early stopping!\")\n",
    "                    break\n",
    "        # 每次test之后loss_sum置零\n",
    "        total_loss = 0.0\n",
    "        test_time = time.time()\n",
    "        print(\"time interval: %.4f min\" % ((test_time-start_time)/60.0))\n",
    "        sys.stdout.flush()\n",
    "    if iter >=  10000: # 超过最大迭代次数，退出训练\n",
    "        break\n",
    "\n",
    "load_model(model, log.best_model_path)\n",
    "model.eval()\n",
    "\n",
    "# 训练结束后用valid_data测试一次\n",
    "metrics = evaluate(model, valid_data,50,args=args)\n",
    "print(', '.join(['Valid ' + key + ': %.6f' % value for key, value in metrics.items()]))\n",
    "# 训练结束后用test_data测试一次\n",
    "print(\"Test result:\")\n",
    "metrics = evaluate(model, test_data,5,args=args)\n",
    "for key, value in metrics.items():\n",
    "    output = 'test ' + key + '@5' + '=%.6f' % value\n",
    "    print(output)\n",
    "    log.write_str(output)\n",
    "metrics = evaluate(model, test_data,10,args=args)\n",
    "for key, value in metrics.items():\n",
    "    output = 'test ' + key + '@10' + '=%.6f' % value\n",
    "    print(output)\n",
    "    log.write_str(output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a996f4-f0f5-4fff-b64c-ae3db7e40e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyp",
   "language": "python",
   "name": "dyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
